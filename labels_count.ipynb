{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import aug_util as aug\n",
    "import wv_util as wv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601937/601937 [00:03<00:00, 153862.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading our labels\n",
    "_, chips1, classes1 = wv.get_labels('/data/zjc4//xView_train.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped classes [1,2,3,4,5]\n",
    "grouped_classes = [[11,12],[13],[17,18,20,21],\\\n",
    "       [19,23,24,25,28,29,60,61,65,26],[41,42,50,40,44,45,47,49]]\n",
    "def filterChips(chips,classes):\n",
    "    # Given train_ind, filter chips,classes\n",
    "    np.chips\n",
    "    pass\n",
    "def transpose_class_counts(chips,classes):\n",
    "    chip_names = np.unique(chips) \n",
    "    results = np.zeros((len(chip_names),5))\n",
    "    chip_strs = []\n",
    "    for c_idx, c in tqdm.tqdm(enumerate(chip_names)):\n",
    "        chip_strs.append(c)\n",
    "        classes_chip = classes[chips==c]\n",
    "        idx_filter = np.isin(classes_chip,grouped_classes[0])\n",
    "        # initialize to all false\n",
    "        for i,gc in (enumerate(grouped_classes)):\n",
    "            is_in_idxs = np.isin(classes_chip,gc)\n",
    "            classes_chip[is_in_idxs] = i\n",
    "            idx_filter = np.logical_or(idx_filter,is_in_idxs)\n",
    "        classes_chip = classes_chip[idx_filter]\n",
    "        labels, counts = np.unique(classes_chip,return_counts=True)\n",
    "        for label_idx,label in enumerate(labels):\n",
    "            results[int(c_idx),int(label)] = counts[label_idx]\n",
    "            pass\n",
    "    chip_strs_col = np.array(chip_strs).reshape(-1,1)\n",
    "    return (np.hstack((chip_strs_col,results)))\n",
    "\n",
    "def indToTifName(data, inds):\n",
    "    res = []\n",
    "    for ind in inds:\n",
    "        res.append(data[ind][0])\n",
    "    return res\n",
    "\n",
    "def showDistribution(data, selected_indexes):\n",
    "    res = []\n",
    "    total = 0\n",
    "    class_num = len(data[0])\n",
    "    for i in range(class_num):\n",
    "        for index in selected_indexes:\n",
    "            total += float(data[index][i])\n",
    "    for i in range(class_num):\n",
    "        total_of_this_class = 0\n",
    "        for index in selected_indexes:\n",
    "            total_of_this_class += float(data[index][i])\n",
    "        res.append(float(total_of_this_class)/total)\n",
    "    return res\n",
    "\n",
    "def checkThreshold(distr1, distr2, thres):\n",
    "    if (len(distr1) != len(distr2)):\n",
    "        print(\"columns' numbers don't fit.\")\n",
    "        return -1\n",
    "    for i in range(len(distr1)):\n",
    "        diff = abs(distr1[i] - distr2[i])\n",
    "        if diff > thres:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def findBalance(data, train_percent, thres):\n",
    "    tifs = len(data)\n",
    "    class_num = len(data[0])\n",
    "    for i in range(1000000):\n",
    "        tr_set, te_set = train_test_split(np.array(list(range(len(data)))),\\\n",
    "                                          test_size=1-train_percent)\n",
    "        tr_d = showDistribution(data, tr_set)\n",
    "        te_d = showDistribution(data, te_set)\n",
    "        check = checkThreshold(tr_d, te_d, thres)\n",
    "        if (check == -1):\n",
    "            return -1\n",
    "        elif (check == True):\n",
    "            return tr_set, te_set\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 1612.02it/s]\n",
      "13it [00:00, 2882.23it/s]\n"
     ]
    }
   ],
   "source": [
    "def splitTrainValidTest(all_chips,all_classes):\n",
    "    # make the table where filename is rowwise, columns are class\n",
    "    s_chips = all_chips\n",
    "    s_classes = all_classes\n",
    "    # Count number of classes\n",
    "    results = transpose_class_counts(s_chips,s_classes)\n",
    "    train_ind, test_ind = findBalance(results[:,1:], 0.7, 0.02)\n",
    "    test_tifs = indToTifName(results, test_ind)\n",
    "    \n",
    "    # Split training set into train and validation\n",
    "    train_tifs = indToTifName(results, train_ind)\n",
    "    train_mask = np.isin(s_chips,train_tifs)\n",
    "    \n",
    "    # Find split for training and validation\n",
    "    train_chips = s_chips[train_mask]\n",
    "    train_classes = s_classes[train_mask]\n",
    "    \n",
    "    train_results = transpose_class_counts(train_chips,train_classes)\n",
    "    train_ind, valid_ind = findBalance(train_results[:,1:], 0.7, 0.02)\n",
    "    # export new train and valid tif labels\n",
    "    train_tifs = indToTifName(train_results, train_ind)\n",
    "    valid_tifs = indToTifName(train_results, valid_ind)\n",
    "    return (train_tifs,valid_tifs, test_tifs)\n",
    "\n",
    "idxs = range(0,40000)\n",
    "string_sets = [\"train\",\"valid\",\"test\"]\n",
    "data_sets = splitTrainValidTest(chips1[idxs],classes1[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,str_set in enumerate(string_sets):\n",
    "    with open(\"{}_tifs.pkl\".format(str_set),\"wb\") as f:\n",
    "        pickle.dump(data_sets[idx],f)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print(np.nonzero(np.isin(data_sets[0],data_sets[1])))\n",
    "print(np.nonzero(np.isin(data_sets[0],data_sets[2])))\n",
    "print(np.nonzero(np.isin(data_sets[1],data_sets[2])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
